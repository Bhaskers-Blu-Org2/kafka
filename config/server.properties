#AzPubSub Settings

auto.leader.rebalance.enable=true
# [AzPubSub] Disable auto creation of topic from producer
auto.create.topics.enable=false
# [AzPubSub] Disable broker id generation. Pick the id from machines.csv
broker.id.generation.enable=false

controller.socket.timeout.ms=30000
controlled.shutdown.enable=true

# [AzPubSub] consumer group session timeout
group.max.session.timeout.ms=600000

# [AzPubSub]  TODO : Needs to be updated
inter.broker.protocol.version=0.10.1

# AP metrics settings
kafka.metrics.polling.interval.secs=30
# kafka.metrics.reporters=com.microsoft.kafka.KafkaAPMetricsReporter

# log cleaner settings
log.cleaner.enable=true
# [AzPubSub] - To be reviewed
log.cleaner.threads=8

#* Ensure compaction runs continuously
# reference : https://www.confluent.io/blog/handling-gdpr-log-forget/
log.cleaner.min.cleanable.ratio = 0.01
#* [AzPubSub] log cleaner throttle to 5MB/s
log.cleaner.io.max.bytes.per.second=5000000

log.cleanup.policy=delete

#* [AzPubSub] - To be reviewed
log.flush.interval.messages=20000
log.flush.scheduler.interval.ms=2000

# [AzPubSub] - 1 day
log.retention.hours=24

# [AzPubSub]
log.retention.check.interval.ms=120000

log.index.interval.bytes=4096
log.index.size.max.bytes=10485760
log.roll.hours=168

# [AzPubSub] - To be reviewed
log.message.timestamp.type=LogAppendTime

# [AzPubSub] - To be reviewed
log.message.format.version=0.10.1

# [AzPubSub] segment size by default to 1Gb
log.segment.bytes=1073741824

#* [AzPubSub] - Changed to default
message.max.bytes=1000012

# [AzPubSub] - To be reviewed
num.io.threads=80
# [AzPubSub] - Updated during connection stress testing.
num.network.threads=400
num.partitions=1
# [AzPubSub] - To be reviewed
num.recovery.threads.per.data.dir=8
# [AzPubSub] - Updated during throughput performance testing.
num.replica.fetchers=40


# replica manager fetch settings
# [AzPubSub] - To be reviewed
replica.fetch.min.bytes=50000
# [AzPubSub] - To be reviewed
replica.fetch.max.bytes=20000000
# [AzPubSub] - To be reviewed
replica.fetch.wait.max.ms=500
replica.high.watermark.checkpoint.interval.ms=5000
replica.socket.timeout.ms=30000
# [AzPubSub] - To be reviewed
replica.socket.receive.buffer.bytes=65536000

replica.lag.time.max.ms=10000

# Socket buffer settings
# [AzPubSub] changed from 100KB to 800MB
socket.send.buffer.bytes=800971520
# [AzPubSub] changed from 64KB to 800MB
socket.receive.buffer.bytes=800971520
# [AzPubSub] changed from 100MB to 500MB
socket.request.max.bytes=536870912

# SSL Setting
#ssl.protocol=SSL
security.inter.broker.protocol=PLAINTEXT
#ssl.keystore.type=Windows-MY
#ssl.keymanager.algorithm=APPKI
#ssl.trustmanager.algorithm=APPKI
listeners=PLAINTEXT://127.0.0.1:9092,SSL://127.0.0.1:9093,SASL_PLAINTEXT://127.0.0.1:9095
ssl.appki.provider.class=com.microsoft.autopilot.azpubsub.APPKIProvider
sasl.enabled.mechanisms=PLAIN
authorizer.class.name=kafka.security.auth.AzPubSubAclAuthorizer

# [AzPubSub] changed from 500 to 20000
queued.max.requests=20000

# [AzPubSub] changed from 6sec to 60sec
zookeeper.connection.timeout.ms=60000

# Below settings are dynamically modified during service start up
#Zk Connection settings
zookeeper.connect=localhost:2181
host.name=localhost
broker.id=0
log.dirs=D:\\data\\Kafka\\kafka-logs
